experiment:
  dataset: movielens_1m_bis
  data_config:
    strategy: dataset
    dataset_path: ../data/movielens_1m/dataset.tsv
  prefiltering:
    strategy: iterative_k_core
    core: 10
  splitting:
    save_folder: ../data/movielens_1m/splitting/
    test_splitting:
        strategy: random_subsampling
        folds: 1
        test_ratio: 0.2
    validation_splitting:
        strategy: random_cross_validation
        folds: 5
  top_k: 50
  evaluation:
    simple_metrics: [nDCG, ACLT, APLT, ARP, PopREO]
    complex_metrics:
    - metric: UserMADrating
      clustering_name: Happiness
      clustering_file: ../data/movielens_1m/u_happy.tsv
    - metric: ItemMADrating
      clustering_name: ItemPopularity
      clustering_file: ../data/movielens_1m/i_pop.tsv
    - metric: REO
      clustering_name: ItemPopularity
      clustering_file: ../data/movielens_1m/i_pop.tsv
    - metric: RSP
      clustering_name: ItemPopularity
      clustering_file: ../data/movielens_1m/i_pop.tsv
    - metric: BiasDisparityBD
      user_clustering_name: Happiness
      user_clustering_file: ../data/movielens_1m/u_happy.tsv
      item_clustering_name: ItemPopularity
      item_clustering_file: ../data/movielens_1m/i_pop.tsv
    relevance_threshold: 1
    wilcoxon_test: True
  gpu: 0
  models:
#    NeuMF:
#      meta:
#        hyper_max_evals: 5
#        hyper_opt_alg: tpe
#      lr: [loguniform, -10, -1]
#      batch_size: [128, 256, 512]
#      epochs: 50
#      mf_factors: [quniform, 8, 32, 1]
#      mlp_factors: [8, 16]
#      mlp_hidden_size: [(32, 16, 8), (64, 32, 16)]
#      prob_keep_dropout: 0.2
#      is_mf_train: True
#      is_mlp_train: True
    MultiVAE:
      meta:
        hyper_max_evals: 5
        hyper_opt_alg: tpe
      lr: [0.0005, 0.001, 0.005, 0.01]
      epochs: 50
      batch_size: [128, 256, 512]
      intermediate_dim: [300, 400, 500]
      latent_dim: [100, 200, 300]
      dropout_pkeep: 1
      reg_lambda: [0.1, 0.0, 10]
#    BPRMF:
#      meta:
#        hyper_max_evals: 5
#        hyper_opt_alg: rand
#      lr: [0.0005, 0.001, 0.005, 0.01]
#      batch_size: [128, 256, 512]
#      epochs: 50
#      bias_regularization: 0
#      user_regularization: [0.0025, 0.005, 0.01]
#      positive_item_regularization: [0.0025, 0.005, 0.01]
#      negative_item_regularization: [0.00025, 0.0005, 0.001]
#      update_negative_item_factors: True
#      update_users: True
#      update_items: True
#      update_bias: True